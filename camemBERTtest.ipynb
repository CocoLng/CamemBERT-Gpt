{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79ce2b36-e49c-4869-9daa-b6a41ea26134",
   "metadata": {},
   "source": [
    "# 0. Testing environnement and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "923b6aa7-8e24-48fa-b3be-8882c6cb8a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import pytorch_lightning as pl\n",
    "    import transformers\n",
    "    import datasets\n",
    "    print(\"Import successful\")\n",
    "except ModuleNotFoundError :\n",
    "    !./create_conda_env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a0be9-b071-4f8d-a8f2-c8f075054535",
   "metadata": {},
   "source": [
    "# 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5a41ab78-4b7f-4351-b219-de17ecd88d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def DL_oscar_subset(n_subset:int=1e4)->pd.DataFrame:\n",
    "    dataset_stream = load_dataset(\"oscar\", \"unshuffled_deduplicated_fr\", split=\"train\", streaming=True)\n",
    "    \n",
    "    subset = []\n",
    "    \n",
    "    for i, example in tqdm(enumerate(dataset_stream), total=n_subset):\n",
    "        subset.append(example)\n",
    "        if i+1 >= n_subset:\n",
    "            break\n",
    "    return pd.DataFrame(subset)\n",
    "\n",
    "def save_dataset(dataset, name=\"oscar_subset.csv\"):\n",
    "    dataset.to_csv(name, index=False)\n",
    "\n",
    "\n",
    "def get_oscar_dataset(n_subset=1e4, name=\"oscar_subset.csv\"):\n",
    "    file_path = Path.cwd() / name\n",
    "    \n",
    "    # Si le fichier n'existe pas, on le télécharge\n",
    "    if not file_path.exists():\n",
    "        print(f\"Le fichier {name} n'existe pas. Téléchargement en cours...\")\n",
    "        subset = DL_oscar_subset(n_subset)\n",
    "        save_dataset(subset)\n",
    "        print(\"Téléchargement et enregistrement du dataset effectués.\")\n",
    "    \n",
    "    # Chargement du dataset\n",
    "    dataset = pd.read_csv(name)\n",
    "    \n",
    "    if len(dataset) < n_subset:\n",
    "        print(f\"Le dataset contient moins de {n_subset} exemples. Téléchargement supplémentaire...\")\n",
    "        subset = DL_oscar_subset(n_subset)\n",
    "        save_dataset(subset)\n",
    "        dataset = pd.read_csv(name)\n",
    "    \n",
    "    # Retourne un sous-ensemble du dataset (limité à n_subset exemples)\n",
    "    return dataset.head(int(n_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b7496ef9-a661-4ead-ae98-27e99b9dc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subset = 1.2e4\n",
    "dataset = get_oscar_dataset(n_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8698ff99-2988-4962-ac21-0bafffd0ba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Média de débat d'idées, de culture et de litté...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24 janv. 2018 Sources de donnéesData Sources. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sous-forums: Abstrait, Architecture (intérieur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19h45 : buffet populaire : repas ouverts aux f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Greg est un lycéen introverti, adepte de l’aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>11995</td>\n",
       "      <td>Coiffures pour les femmes âgées visent à rendr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>11996</td>\n",
       "      <td>Ce billet a été publié dans Photo et taggé ave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>11997</td>\n",
       "      <td>John Hurt, d'abord, immense acteur anglais mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>11998</td>\n",
       "      <td>Voici un aperçu de l’atelier balle de gages, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>11999</td>\n",
       "      <td>Villa das Rosas est un petit domaine de 3500 m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text\n",
       "0          0  Média de débat d'idées, de culture et de litté...\n",
       "1          1  24 janv. 2018 Sources de donnéesData Sources. ...\n",
       "2          2  Sous-forums: Abstrait, Architecture (intérieur...\n",
       "3          3  19h45 : buffet populaire : repas ouverts aux f...\n",
       "4          4  Greg est un lycéen introverti, adepte de l’aut...\n",
       "...      ...                                                ...\n",
       "11995  11995  Coiffures pour les femmes âgées visent à rendr...\n",
       "11996  11996  Ce billet a été publié dans Photo et taggé ave...\n",
       "11997  11997  John Hurt, d'abord, immense acteur anglais mor...\n",
       "11998  11998  Voici un aperçu de l’atelier balle de gages, u...\n",
       "11999  11999  Villa das Rosas est un petit domaine de 3500 m...\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc2fada-1fda-4f6f-9fe5-ab155c1a81c0",
   "metadata": {},
   "source": [
    "# 2. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1d0c2776-a145-4bf8-8126-fd3c64f637e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import RobertaConfig\n",
    "from transformers import CamembertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "15af49f9-f935-4c77-8327-6b607265c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1c0dc21a-0676-4741-96c5-bfa3fe4e6b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamembertModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # Embedding layers\n",
    "        self.embeddings = nn.Embedding(self.config.vocab_size, \n",
    "                                       self.config.hidden_size)\n",
    "        self.position_embeddings = nn.Embedding(self.config.max_position_embeddings, \n",
    "                                                self.config.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(d_model=self.config.hidden_size, \n",
    "                                       nhead=self.config.num_attention_heads, \n",
    "                                       dim_feedforward=self.config.intermediate_size, \n",
    "                                       dropout=self.config.hidden_dropout_prob)\n",
    "            for _ in range(self.config.num_hidden_layers)\n",
    "        ])\n",
    "        \n",
    "        self.linear = nn.Linear(self.config.hidden_size,\n",
    "                                self.config.vocab_size)  # Projection to vocab_size\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Compute embeddings\n",
    "        seq_length = input_ids.size(0)\n",
    "        position_ids = torch.arange(seq_length, device=input_ids.device).unsqueeze(0)\n",
    "        embeddings = self.embeddings(input_ids) + self.position_embeddings(position_ids)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        \n",
    "        # Pass through Transformer encoder layers\n",
    "        hidden_states = embeddings\n",
    "        for layer in self.encoder_layers:\n",
    "            hidden_states = layer(hidden_states)\n",
    "        \n",
    "        logits = self.linear(hidden_states)  # Output shape: (batch_size, seq_len, vocab_size)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0ce503a4-161d-497e-8863-0fcbb7d5756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type camembert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"architectures\": [\n",
       "    \"CamembertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 5,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 6,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32005\n",
       "}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(\"camembert-base\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "915d5e65-78ae-4293-b2ab-8aac60212878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertModel(\n",
       "  (embeddings): Embedding(32005, 768)\n",
       "  (position_embeddings): Embedding(514, 768)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-11): 12 x TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=32005, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CamembertModel(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09bcc7-763d-4ead-af8f-7b50f7d5841c",
   "metadata": {},
   "source": [
    "# 3. Pre-Processe data\n",
    "## 3.1 preprocesse function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78a1cef2-021f-4671-9f8e-ec8038763c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    5, 32004,     7,   404,   136,   198,   106,     6,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1],\n",
       "       [    5,   121,    11,   660,  1891,    17,    11,  6031, 32004,\n",
       "            9,     6,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_and_mask_data(texts, tokenizer, max_length=128, mlm_probability=0.15):\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    labels = input_ids.clone()\n",
    "\n",
    "    # Create a mask\n",
    "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
    "    special_tokens_mask = [\n",
    "        tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
    "    ]\n",
    "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
    "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
    "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
    "\n",
    "    # Replace masked input tokens with tokenizer.mask_token_id\n",
    "    input_ids[masked_indices] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    return input_ids, attention_mask, labels\n",
    "\n",
    "\n",
    "# Example preprocessing step\n",
    "texts = [\n",
    "    \"Bonjour, comment ça va ?\", \n",
    "    \"J'aime apprendre l'intelligence artificielle.\"\n",
    "]\n",
    "processed_data = preprocess_and_mask_data(texts, tokenizer)\n",
    "np.array(processed_data)[0,:,:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37368668-26de-4c55-b52e-dcf51967654e",
   "metadata": {},
   "source": [
    "## 3.2 Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9d45a4c6-7be2-46ef-b159-6c737238cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OscarDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=128, mlm_probability=0.15):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.max_length = max_length\n",
    "        self.mlm_probability = mlm_probability\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        input_ids, attention_mask, labels = preprocess_and_mask_data(\n",
    "            [text], self.tokenizer, self.max_length, self.mlm_probability\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': input_ids.squeeze(0),\n",
    "            'attention_mask': attention_mask.squeeze(0),\n",
    "            'labels': labels.squeeze(0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "899ba55b-7ed1-4060-ba4d-54304a03f409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 10000, 2000)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = dataset['text']\n",
    "sample_texts = texts.sample(frac=1)\n",
    "\n",
    "p = 0.83334\n",
    "train_size = int(len(texts)*p)\n",
    "test_size = len(texts) - train_size\n",
    "\n",
    "train_texts = sample_texts.head(train_size)\n",
    "test_texts = sample_texts.tail(test_size)\n",
    "\n",
    "len(texts), len(train_texts), len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7f534fea-290f-4ffc-88c8-2ca57d3120d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataset = OscarDataset(train_texts, tokenizer) # dont try to use this :/\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataset = OscarDataset(test_texts, tokenizer) # dont try to use this :/\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28939313-cc0d-4cf0-a784-b3bd4e8bc96d",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "## 4.1 With pytorch-lightning : Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bf358137-90b1-4e54-8706-ebc76b673afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() # ouch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8bc19469-5b8d-455f-ba5f-6358a11d60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class CamembertTrainer(pl.LightningModule):\n",
    "    def __init__(self, model, tokenizer, learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        return self.model(input_ids)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, labels = batch[\"input_ids\"], batch[\"labels\"]\n",
    "        outputs = self.model(input_ids)\n",
    "        loss = self.loss_fn(outputs.view(-1, config.vocab_size), labels.view(-1))\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f33a38bc-f946-4dae-b102-7905ba00c575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | model   | CamembertModel   | 134 M  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "134 M     Trainable params\n",
      "0         Non-trainable params\n",
      "134 M     Total params\n",
      "538.564   Total estimated model params size (MB)\n",
      "127       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1250/1250 [13:39<00:00,  1.53it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1250/1250 [13:48<00:00,  1.51it/s, v_num=3]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "%%time \n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(CamembertTrainer(model, tokenizer), train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaabe45-330f-4b46-a6c5-246180282542",
   "metadata": {},
   "source": [
    "## 4.2 Regular pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6351ed9-dcab-42d1-bbaf-672bfafe48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from torch.optim import AdamW\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "# Load CamembertModel from the earlier definition\n",
    "config = RobertaConfig.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel(\n",
    "    vocab_size=config.vocab_size,\n",
    "    max_position_embeddings=config.max_position_embeddings,\n",
    "    num_hidden_layers=config.num_hidden_layers,\n",
    "    hidden_size=config.hidden_size,\n",
    "    num_attention_heads=config.num_attention_heads,\n",
    "    intermediate_size=config.intermediate_size,\n",
    "    hidden_dropout_prob=config.hidden_dropout_prob,\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 1\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Move inputs and labels to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs.view(-1, config.vocab_size), labels.view(-1))\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1} | Loss: {epoch_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37886553-7983-438d-91d0-fc1bb4fa84a8",
   "metadata": {},
   "source": [
    "# 5. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a4af8409-7fe2-475f-85e4-85afcb9b1f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/camembert_custom_tokenizer/tokenizer_config.json',\n",
       " './models/camembert_custom_tokenizer/special_tokens_map.json',\n",
       " './models/camembert_custom_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = './models/camembert_custom_model.pth'\n",
    "tokenizer_save_path = './models/camembert_custom_tokenizer'\n",
    " \n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de2b6b-012e-44e2-a54a-f4c728cfee30",
   "metadata": {},
   "source": [
    "# 6. Load & Tets model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c3435615-db5a-4f98-8106-b37b685f9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8247/2418509839.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_load.load_state_dict(torch.load(model_save_path))\n"
     ]
    }
   ],
   "source": [
    "model_load = CamembertModel(config) # init\n",
    "\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "model_load.load_state_dict(torch.load(model_save_path))\n",
    "model_load.eval()  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8681f8ce-7bbe-4124-a6f1-02bb7f110091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_load, dataloader, device):\n",
    "    total_loss = 0\n",
    "    total_examples = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        with torch.inference_mode(): \n",
    "            outputs = model(input_ids)\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "        # output xhape (batch_size, seq_len, vocab_size)\n",
    "        logits = outputs.view(-1, model.config.vocab_size)\n",
    "        labels = labels.view(-1)\n",
    "        \n",
    "        loss = loss_fn(logits, labels)\n",
    "        total_loss += loss.item() * input_ids.size(0) \n",
    "        total_examples += input_ids.size(0) \n",
    "\n",
    "    avg_loss = total_loss / total_examples\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e001e615-36b4-48e3-8df9-f7f51cf4fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 250/250 [01:29<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perte moyenne sur le dataset : 10.52037271118164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "avg_loss = evaluate_model(model_load, test_dataloader, device)\n",
    "print(f\"Perte moyenne sur le dataset : {avg_loss}\") # 10.51747866821289 ca marche mais bon 1 epoch sur 1000 exemples pour l'entrainement (pas d'erreur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bfc89-fd34-46aa-a057-aa5d11a4af30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (camemBERTenv)",
   "language": "python",
   "name": "camembertenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
